{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-03-12T12:02:53.243355Z",
     "iopub.status.busy": "2025-03-12T12:02:53.243079Z",
     "iopub.status.idle": "2025-03-12T12:03:04.111843Z",
     "shell.execute_reply": "2025-03-12T12:03:04.110703Z",
     "shell.execute_reply.started": "2025-03-12T12:02:53.243333Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# !pip install torch==2.5.1 torchvision==0.20.1 torchaudio==2.5.1 --index-url https://download.pytorch.org/whl/cu118\n",
    "# !pip install torch_geometric\n",
    "# # Optional dependencies:\n",
    "# !pip install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.5.0+cu118.html\n",
    "# !pip install pandas numpy torch torch_geometric networkx matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-12T12:03:07.823960Z",
     "iopub.status.busy": "2025-03-12T12:03:07.823593Z",
     "iopub.status.idle": "2025-03-12T12:03:07.829423Z",
     "shell.execute_reply": "2025-03-12T12:03:07.828584Z",
     "shell.execute_reply.started": "2025-03-12T12:03:07.823926Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import HeteroConv, SAGEConv\n",
    "from torch_geometric.data import HeteroData\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import os\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import multiprocessing\n",
    "from collections import defaultdict, Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-12T12:03:07.830850Z",
     "iopub.status.busy": "2025-03-12T12:03:07.830605Z",
     "iopub.status.idle": "2025-03-12T12:03:07.851821Z",
     "shell.execute_reply": "2025-03-12T12:03:07.850895Z",
     "shell.execute_reply.started": "2025-03-12T12:03:07.830830Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "import torch.backends.cudnn as cudnn\n",
    "cudnn.benchmark = True\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "torch.backends.cuda.enable_mem_efficient_sdp(False)\n",
    "torch.backends.cuda.enable_flash_sdp(False)\n",
    "torch.backends.cuda.enable_math_sdp(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class to create Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-12T12:03:07.853135Z",
     "iopub.status.busy": "2025-03-12T12:03:07.852825Z",
     "iopub.status.idle": "2025-03-12T12:03:07.868762Z",
     "shell.execute_reply": "2025-03-12T12:03:07.867943Z",
     "shell.execute_reply.started": "2025-03-12T12:03:07.853104Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def process_chunk(df_chunk):\n",
    "    user_currency_counter = defaultdict(Counter)\n",
    "    user_location_counter = defaultdict(Counter)\n",
    "    \n",
    "    for _, row in df_chunk.iterrows():\n",
    "        sender = row['Sender_account']\n",
    "        receiver = row['Receiver_account']\n",
    "        \n",
    "        # For sender\n",
    "        user_currency_counter[sender][row['Payment_currency']] += 1\n",
    "        user_location_counter[sender][row['Sender_bank_location']] += 1\n",
    "        \n",
    "        # For receiver\n",
    "        user_currency_counter[receiver][row['Received_currency']] += 1\n",
    "        user_location_counter[receiver][row['Receiver_bank_location']] += 1\n",
    "    \n",
    "    return user_currency_counter, user_location_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-12T12:03:07.869832Z",
     "iopub.status.busy": "2025-03-12T12:03:07.869573Z",
     "iopub.status.idle": "2025-03-12T12:03:07.888475Z",
     "shell.execute_reply": "2025-03-12T12:03:07.887645Z",
     "shell.execute_reply.started": "2025-03-12T12:03:07.869811Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class HetroGraphDataset:\n",
    "    def __init__(self, csv_file, graph_path, force_recreate=False):\n",
    "        self.path = csv_file\n",
    "        self.graph_path = graph_path\n",
    "        self.graph = HeteroData()\n",
    "        if os.path.exists(self.graph_path) and not force_recreate:\n",
    "            print(f\"Graph file found at {self.graph_path}. Loading existing graph...\")\n",
    "            self.graph = torch.load(self.graph_path)\n",
    "            self.n_transactions = self.graph['transaction'].num_nodes\n",
    "            self.user_map = {i: idx for idx, i in enumerate(range(self.graph['user'].num_nodes))}\n",
    "            print(\"Graph loaded successfully.\")\n",
    "        else:\n",
    "            print(f\"Creating graph from CSV (force_recreate={force_recreate})...\")\n",
    "            self.df = self._read_csv_file()\n",
    "            self.n_transactions = len(self.df)\n",
    "            self.user_map = {}\n",
    "            self.create_mapping()\n",
    "            print(\"Start Creating Graph...\")\n",
    "            steps = [\"Initializing Graph Nodes\", \"Adding Edges\"]\n",
    "            with tqdm(total=len(steps), desc=\"Graph Creation Progress\") as pbar:\n",
    "                self.initalize_graph_nodes()\n",
    "                pbar.update(1)\n",
    "                self.add_edges()\n",
    "                pbar.update(1)\n",
    "            print(\"Graph creation completed.\")\n",
    "            self.save_graph(self.graph_path)\n",
    "\n",
    "    def _read_csv_file(self):\n",
    "        print(\"Reading the Data ...\")\n",
    "        dtype = {\n",
    "            'Sender_account': 'int64',\n",
    "            'Receiver_account': 'int64',\n",
    "            'Sender_bank_location': 'int8',\n",
    "            'Receiver_bank_location': 'int8',\n",
    "            'Payment_currency': 'int8',\n",
    "            'Received_currency': 'int8',\n",
    "            'Amount': 'float32',\n",
    "            'Payment_type': 'int8',\n",
    "            'Year': 'int16',\n",
    "            'Month': 'int8',\n",
    "            'Day': 'int8',\n",
    "            'Is_laundering': 'int8',\n",
    "            'Laundering_type': 'int8'\n",
    "        }\n",
    "        return pd.read_csv(self.path, dtype=dtype)\n",
    "\n",
    "    def create_mapping(self):\n",
    "        print(\"Computing most frequent currency and location for each user...\")\n",
    "        \n",
    "        # Create mapping from account numbers to user indices\n",
    "        all_accounts = set(self.df['Sender_account'].unique()).union(set(self.df['Receiver_account'].unique()))\n",
    "        self.user_map = {acc: i for i, acc in enumerate(sorted(all_accounts))}\n",
    "        print(f\"Number of users = {len(self.user_map)}\")\n",
    "        print(f\"Number of transactions = {self.n_transactions}\")\n",
    "        \n",
    "        # Determine number of processes\n",
    "        num_processes = multiprocessing.cpu_count()\n",
    "        \n",
    "        # Split dataframe into chunks\n",
    "        indices = np.array_split(self.df.index, num_processes)\n",
    "        chunks = [self.df.loc[idx] for idx in indices]\n",
    "        \n",
    "        # Use Pool to map over chunks with progress bar\n",
    "        with multiprocessing.Pool() as pool:\n",
    "            with tqdm(total=len(chunks), desc=\"Processing chunks\") as pbar:\n",
    "                results = list(pool.imap(process_chunk, chunks))\n",
    "        \n",
    "        # Combine partial counters\n",
    "        total_user_currency_counter = defaultdict(Counter)\n",
    "        total_user_location_counter = defaultdict(Counter)\n",
    "        \n",
    "        for chunk_currency_counter, chunk_location_counter in results:\n",
    "            for user, counter in chunk_currency_counter.items():\n",
    "                total_user_currency_counter[user].update(counter)\n",
    "            for user, counter in chunk_location_counter.items():\n",
    "                total_user_location_counter[user].update(counter)\n",
    "        \n",
    "        # Find most frequent currency and location for each user\n",
    "        self.user_currency = {}\n",
    "        self.user_location = {}\n",
    "        for account in self.user_map:\n",
    "            currency_counter = total_user_currency_counter[account]\n",
    "            location_counter = total_user_location_counter[account]\n",
    "            \n",
    "            if currency_counter:\n",
    "                most_frequent_currency = currency_counter.most_common(1)[0][0]\n",
    "            else:\n",
    "                most_frequent_currency = 0\n",
    "            if location_counter:\n",
    "                most_frequent_location = location_counter.most_common(1)[0][0]\n",
    "            else:\n",
    "                most_frequent_location = 0\n",
    "            self.user_currency[account] = most_frequent_currency\n",
    "            self.user_location[account] = most_frequent_location\n",
    "\n",
    "    def initalize_graph_nodes(self):\n",
    "        self.graph['transaction'].num_nodes = self.n_transactions\n",
    "        payment_type_values = self.df['Payment_type'].values\n",
    "        payment_type_onehot = torch.nn.functional.one_hot(\n",
    "            torch.from_numpy(payment_type_values).to(dtype=torch.int64),\n",
    "            num_classes=7  # Adjust if different\n",
    "        )\n",
    "        amount = torch.from_numpy(self.df['Amount'].values).unsqueeze(1)\n",
    "        transaction_features = torch.cat([amount, payment_type_onehot], dim=1).to(dtype=torch.float32)\n",
    "        self.graph['transaction'].x = transaction_features\n",
    "        self.graph['transaction'].date = [\n",
    "            f\"{int(row['Year'])}-{int(row['Month']):02d}-{int(row['Day']):02d}\"\n",
    "            for _, row in self.df.iterrows()\n",
    "        ]\n",
    "        self.graph['transaction'].is_laundering = torch.from_numpy(self.df['Is_laundering'].values).to(dtype=torch.int8)\n",
    "        self.graph['user'].num_nodes = len(self.user_map)\n",
    "        user_currency_values = [self.user_currency[acc] for acc in self.user_map]\n",
    "        user_currency_onehot = torch.nn.functional.one_hot(\n",
    "            torch.from_numpy(np.array(user_currency_values)).to(dtype=torch.int64),\n",
    "            num_classes=13  # Adjust if different\n",
    "        )\n",
    "        user_location_values = [self.user_location[acc] for acc in self.user_map]\n",
    "        user_location_onehot = torch.nn.functional.one_hot(\n",
    "            torch.from_numpy(np.array(user_location_values)).to(dtype=torch.int64),\n",
    "            num_classes=18  # Adjust if different\n",
    "        )\n",
    "        user_features = torch.cat([user_currency_onehot, user_location_onehot], dim=1).to(dtype=torch.float32)\n",
    "        self.graph['user'].x = user_features\n",
    "\n",
    "    def add_edges(self):\n",
    "        sender_to_transaction = torch.tensor(\n",
    "            [[self.user_map[row['Sender_account']], i] for i, (_, row) in enumerate(self.df.iterrows())],\n",
    "            dtype=torch.long\n",
    "        ).t()\n",
    "        self.graph['user', 'sends', 'transaction'].edge_index = sender_to_transaction\n",
    "        transaction_to_receiver = torch.tensor(\n",
    "            [[i, self.user_map[row['Receiver_account']]] for i, (_, row) in enumerate(self.df.iterrows())],\n",
    "            dtype=torch.long\n",
    "        ).t()\n",
    "        self.graph['transaction', 'received_by', 'user'].edge_index = transaction_to_receiver\n",
    "\n",
    "    def save_graph(self, path):\n",
    "        print(f\"Saving graph to {path}...\")\n",
    "        torch.save(self.graph, path)\n",
    "        print(f\"Graph saved successfully to {path}\")\n",
    "\n",
    "    def info_about_graph(self):\n",
    "        print(\"Heterogeneous Graph Summary:\")\n",
    "        print(self.graph)\n",
    "        \n",
    "        print(\"\\nNode counts:\")\n",
    "        print(f\"user: {self.graph['user'].num_nodes}\")\n",
    "        print(f\"Transactions: {self.graph['transaction'].num_nodes}\")\n",
    "        \n",
    "        print(\"\\nEdge types and counts:\")\n",
    "        for edge_type in self.graph.edge_types:\n",
    "            print(f\"{edge_type}: {self.graph[edge_type].edge_index.shape[1]} edges\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-12T12:06:18.288153Z",
     "iopub.status.busy": "2025-03-12T12:06:18.287801Z",
     "iopub.status.idle": "2025-03-12T12:06:21.622321Z",
     "shell.execute_reply": "2025-03-12T12:06:21.621435Z",
     "shell.execute_reply.started": "2025-03-12T12:06:18.288124Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph file found at /kaggle/input/complete-graph/complete-graph.pt. Loading existing graph...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-21-ab79a006ba89>:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.graph = torch.load(self.graph_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph loaded successfully.\n",
      "Transaction features shape: torch.Size([9504852, 8])\n",
      "User features shape: torch.Size([855460, 31])\n",
      "Heterogeneous Graph Summary:\n",
      "HeteroData(\n",
      "  transaction={\n",
      "    num_nodes=9504852,\n",
      "    x=[9504852, 8],\n",
      "    date=[9504852],\n",
      "    is_laundering=[9504852],\n",
      "  },\n",
      "  user={\n",
      "    num_nodes=855460,\n",
      "    x=[855460, 31],\n",
      "  },\n",
      "  (user, sends, transaction)={ edge_index=[2, 9504852] },\n",
      "  (transaction, received_by, user)={ edge_index=[2, 9504852] }\n",
      ")\n",
      "\n",
      "Node counts:\n",
      "user: 855460\n",
      "Transactions: 9504852\n",
      "\n",
      "Edge types and counts:\n",
      "('user', 'sends', 'transaction'): 9504852 edges\n",
      "('transaction', 'received_by', 'user'): 9504852 edges\n"
     ]
    }
   ],
   "source": [
    "# Main execution\n",
    "dataset = HetroGraphDataset('/kaggle/input/complete-dataset/data.csv', graph_path='/kaggle/input/complete-graph/complete-graph.pt', force_recreate=True)  # Force recreate to update features\n",
    "data = dataset.graph\n",
    "\n",
    "# Verify feature shapes\n",
    "print(f\"Transaction features shape: {data['transaction'].x.shape}\")\n",
    "print(f\"User features shape: {data['user'].x.shape}\")\n",
    "dataset.info_about_graph()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6754105,
     "sourceId": 10871222,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6812219,
     "sourceId": 10951367,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6823752,
     "sourceId": 10967415,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6851829,
     "sourceId": 11006187,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
